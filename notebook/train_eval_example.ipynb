{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from utils import DataGenerator, read_annotation_lines\n",
    "from models import Yolov4\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "tf.config.experimental.list_physical_devices()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = 'datasets/some_pascalvoc_dataset'\n",
    "\n",
    "PATH_IMG = os.path.join(BASE_DIR, 'JPEGImages/')\n",
    "PATH_CLASS = os.path.join(BASE_DIR, 'labels.txt')\n",
    "PATH_XML = os.path.join(BASE_DIR, 'Annotations/')\n",
    "\n",
    "PATH_ANN = os.path.join(BASE_DIR, 'annotations.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert xml into txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''loads the classes'''\n",
    "def get_classes(classes_path):\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = get_classes(PATH_CLASS)\n",
    "assert len(classes) > 0, 'no class names detected!'\n",
    "print(f'num classes: {len(classes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file\n",
    "list_file = open(PATH_ANN, 'w')\n",
    "\n",
    "for path in glob(os.path.join(PATH_XML, '*.xml')):\n",
    "    in_file = open(path)\n",
    "\n",
    "    # Parse .xml file\n",
    "    tree = ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "    # Write object information to .txt file\n",
    "    file_name = root.find('filename').text\n",
    "    print(file_name)\n",
    "    list_file.write(file_name)\n",
    "    for obj in root.iter('object'):\n",
    "        cls = obj.find('name').text \n",
    "        cls_id = classes.index(cls)\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text), int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text))\n",
    "        list_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))\n",
    "    list_file.write('\\n')\n",
    "list_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines, val_lines = read_annotation_lines(PATH_ANN, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.OneOf([\n",
    "        iaa.Sometimes(0.1, iaa.HorizontalFlip(1)),\n",
    "        iaa.Sometimes(0.1, iaa.VerticalFlip(1)),\n",
    "        iaa.Sometimes(0.1, iaa.Rot90([1])),\n",
    "        iaa.Sometimes(0.1, iaa.Rot90([2])),\n",
    "    ]),\n",
    "\n",
    "    iaa.Sometimes(0.2, iaa.OneOf([\n",
    "        iaa.Crop(px=(5, 16)),\n",
    "        iaa.Affine(\n",
    "            scale={'x': (1, 1.2), 'y': (1, 1.2)},\n",
    "            # translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "            rotate=(-5, 5),\n",
    "            shear=(-10, 10)\n",
    "        ),\n",
    "\n",
    "    ])),\n",
    "\n",
    "    iaa.Sometimes(0.1, ia.augmenters.color.Grayscale(alpha=1)),\n",
    "    iaa.Sometimes(0.1, iaa.AddToHue((-20, 20))),\n",
    "    #     iaa.Sometimes(0.1, ia.augmenters.color.AddToHueAndSaturation((-20, 20))),\n",
    "    iaa.Sometimes(0.1, iaa.AdditiveGaussianNoise(scale=0.01 * 255)),\n",
    "    iaa.Sometimes(0.1, iaa.GammaContrast((0.6, 1.7))),\n",
    "], random_order=False)\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Rot90([1]),\n",
    "], random_order=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_generator_1 = DataGenerator(train_lines, PATH_CLASS, PATH_IMG, batch_size=1, shuffle=True, augmentors=seq)\n",
    "for (image, *_, boxes), _ in train_generator_1:\n",
    "    \n",
    "    image = np.squeeze(image)\n",
    "    boxes = np.squeeze(boxes)\n",
    "    \n",
    "    for box in boxes:\n",
    "        if np.all(box == 0):\n",
    "            break\n",
    "        x1, y1, w, h = box\n",
    "        x1 = int(x1 - w // 2)\n",
    "        x2 = int(x1 + w)\n",
    "        y1 = int(y1 - h // 2)\n",
    "        y2 = int(y1 + h)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines, val_lines = read_annotation_lines(PATH_ANN, test_size = 0.2)\n",
    "#print(train_lines)\n",
    "\n",
    "data_gen_train = DataGenerator(train_lines, PATH_CLASS, PATH_IMG)\n",
    "data_gen_val = DataGenerator(val_lines, PATH_CLASS, PATH_IMG)\n",
    "#print(data_gen_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = '../yolov4.weights'\n",
    "model = Yolov4(weight_path=weight_path, class_name_path=PATH_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'your_save_path/'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    " \n",
    "# filepath = path + 'epoch_{epoch:02d}-val_loss-{val_loss:.4f}.h5'\n",
    "filepath = path + 'model.h5'\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath, monitor = 'val_loss', verbose = 1, save_best_only = True,\n",
    "                    save_weights_only = False, mode = 'auto', period = 1),\n",
    "    ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 5, verbose = 1),\n",
    "    EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 10),\n",
    "    TensorBoard(log_dir = path + '/tensorboard', histogram_freq = 0, write_graph = False, write_images = False),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(data_gen_train, \n",
    "          initial_epoch=0,\n",
    "          epochs=epochs, \n",
    "          val_data_gen=data_gen_val,\n",
    "          callbacks=callbacks)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(path + f'yolov4_e{epochs}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.inference_model.save(path + f'yolov4_e{epochs}_inf.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use get_detection_data_np function in models.py/predict_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'yolov4_100.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Yolov4(class_name_path=PATH_CLASS)\n",
    "model.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob(PATH_IMG + '/*.*')\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ix = random.randint(0, len(filenames) - 1)\n",
    "# ix = 0\n",
    "print(ix, filenames[ix])\n",
    "t1 = time.time()\n",
    "img = cv2.imread(filenames[ix], cv2.IMREAD_UNCHANGED)[:, :, ::-1]\n",
    "img = np.array(img)\n",
    "boxes, scores, labels = model.predict(filenames[ix], random_color=False, plot_img=True, show_text=False)\n",
    "t2 = time.time()\n",
    "\n",
    "print(f'Prediction time : {t2 - t1}')\n",
    "\n",
    "scale = max(img.shape[0:2]) / 416\n",
    "line_width = int(2 * scale)\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "for box, score, label in zip(boxes, scores, labels):\n",
    "    \n",
    "    print(label, score, box)\n",
    "    x1, y1, x2, y2 = box\n",
    "    x1 = int(x1 * w)\n",
    "    x2 = int(x2 * w)\n",
    "    y1 = int(y1 * h)\n",
    "    y2 = int(y2 * h)\n",
    "    color = (255, 0, 0)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), color, line_width)\n",
    "    text = f'{label} {score:.2f}'\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    font_scale = max(0.3 * scale, 0.3)\n",
    "    thickness = max(int(1 * scale), 1)\n",
    "    (text_width, text_height) = cv2.getTextSize(text, font, fontScale=font_scale, thickness=thickness)[0]\n",
    "    cv2.rectangle(img, (x1 - line_width//2, y1 - text_height), (x1 + text_width, y1), color, cv2.FILLED)\n",
    "    cv2.putText(img, text, (x1, y1), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n",
    "    \n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'your_save_path/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_folder_path = os.path.join(path, 'map', 'gt_folder')\n",
    "if not os.path.exists(gt_folder_path):\n",
    "    os.makedirs(gt_folder_path)\n",
    "pred_folder_path = os.path.join(path, 'map', 'pred_folder')\n",
    "if not os.path.exists(pred_folder_path):\n",
    "    os.makedirs(pred_folder_path)\n",
    "    \n",
    "model.export_gt(PATH_ANN, gt_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export_prediction(PATH_ANN, pred_folder_path, PATH_IMG, bs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp_json_folder_path = os.path.join(path, 'map', 'json')\n",
    "if not os.path.exists(temp_json_folder_path):\n",
    "    os.makedirs(temp_json_folder_path)\n",
    "output_files_path = os.path.join(path, 'map')\n",
    "model.eval_map(gt_folder_path, pred_folder_path, temp_json_folder_path, output_files_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import argparse\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setKerasOptions():\n",
    "    K._LEARNING_PHASE = tf.constant(0)\n",
    "    K.set_learning_phase(False)\n",
    "    K.set_learning_phase(0)\n",
    "    K.set_image_data_format('channels_last')\n",
    "\n",
    "\n",
    "def getInputParameters():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--input_model', '-m', required=True, type=str, help='Path to Keras model.')\n",
    "    parser.add_argument('--num_outputs', '-no', required=False, type=int, help='Number of outputs. 1 by default.', default=1)\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "def export_keras_to_tf(input_model, output_model, num_output, custom_metric=None):\n",
    "    print('Loading Keras model: ', input_model)\n",
    "    \n",
    "    if custom_metric is None:\n",
    "        keras_model = load_model(input_model)\n",
    "    else:\n",
    "        keras_model = load_model(input_model, custom_objects=custom_metric)\n",
    "\n",
    "    print(keras_model.summary())\n",
    "\n",
    "    predictions = [None] * num_output\n",
    "    predrediction_node_names = [None] * num_output\n",
    "\n",
    "    for i in range(num_output):\n",
    "        predrediction_node_names[i] = 'output_node' + str(i)\n",
    "        predictions[i] = tf.identity(keras_model.outputs[i], name=predrediction_node_names[i])\n",
    "\n",
    "    sess = K.get_session()\n",
    "\n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), predrediction_node_names)\n",
    "    infer_graph = graph_util.remove_training_nodes(constant_graph) \n",
    "\n",
    "    graph_io.write_graph(infer_graph, '.', output_model, as_text=False)\n",
    "    \n",
    "def export_keras_to_tf_model(keras_model, output_model, num_output):\n",
    "    print('Loading Keras model: ', input_model)\n",
    "\n",
    "    # print(keras_model.summary())\n",
    "\n",
    "    predictions = [None] * num_output\n",
    "    predrediction_node_names = [None] * num_output\n",
    "\n",
    "    for i in range(num_output):\n",
    "        predrediction_node_names[i] = 'output_node' + str(i)\n",
    "        predictions[i] = tf.identity(keras_model.outputs[i], name=predrediction_node_names[i])\n",
    "\n",
    "    sess = K.get_session()\n",
    "\n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), predrediction_node_names)\n",
    "    infer_graph = graph_util.remove_training_nodes(constant_graph) \n",
    "\n",
    "    graph_io.write_graph(infer_graph, '.', output_model, as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'your_save_path/'\n",
    "\n",
    "model_name = 'yolov4_e10.h5'\n",
    "\n",
    "input_model = os.path.join(base_dir, model_name)\n",
    "num_output = 1\n",
    "\n",
    "output_model = os.path.join(base_dir, str(Path(input_model).name) + '.pb')\n",
    "# custom_metric = {'iou': iou}\n",
    "custom_metric = None\n",
    "\n",
    "output_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predrediction_node_names = export_keras_to_tf_model(model.inference_model, output_model, num_output)\n",
    "\n",
    "print('Ouput nodes are:', predrediction_node_names)\n",
    "print('Saved as TF frozen model to: ', output_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
